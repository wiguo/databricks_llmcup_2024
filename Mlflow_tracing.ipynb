{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a907d606-6f78-4230-b190-4a1a1ed2b59e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-community langchain-core sqlalchemy langchain_experimental matplotlib mlflow langgraph fsspec huggingface_hub youtube-search openai langchain-databricks databricks-sdk langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b35c05b0-14f5-40c3-88bb-547e2312707d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71e4b974-fc5f-4941-81cd-f435e95a039a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import langchain\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models import validate_serving_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd034c8-71bd-4454-a0f7-7a3b78f158c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cae45b9e-32bd-4d6b-959f-c3a2df4bbe89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load graph \n",
    "new_app = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7024399-eca4-4606-a7b7-be646a6c9e85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n  ['messages': Array({content: string (required), role: string (required)}) (required)]\noutputs: \n  [string (required)]\nparams: \n  None\n\n"
     ]
    }
   ],
   "source": [
    "######## model signature ######## \n",
    "\n",
    "message = \"get a youtube video on customer service greeting\"\n",
    "input = {\"messages\": [{\"role\": \"user\", \"content\": message}]}\n",
    "output = new_app.invoke(input)\n",
    "signature = infer_signature(input, output)\n",
    "\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fc8bf41-f037-4806-9cb1-43a0fa5a508f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 07:54:01 WARNING mlflow.langchain.databricks_dependencies: Unable to detect Databricks dependencies. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f8f3257de640939b5d957acff65aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'llmcup2024.default.agentqaxv2'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30318c6f6254cb989ef377f31eebe16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'llmcup2024.default.agentqaxv2'.\n2024/10/24 07:54:19 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run welcoming-finch-143 at: https://dbc-b3a32eda-16b0.cloud.databricks.com/ml/experiments/1422264621101654/runs/198b5c50c1a54946aae1b74d24e67a71.\n2024/10/24 07:54:19 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://dbc-b3a32eda-16b0.cloud.databricks.com/ml/experiments/1422264621101654.\n"
     ]
    }
   ],
   "source": [
    "######## Log LangGraph using Model from Code ######## \n",
    "\n",
    "\n",
    "catalog_name = 'llmcup2024'\n",
    "schema_name = \"default\"\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_name = f\"{catalog_name}.{schema_name}.agentqaxv2\"\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    \n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        lc_model=\"./graph\", # Path to our model Python file\n",
    "        artifact_path=\"langgraph\",\n",
    "        registered_model_name= model_name, # Add model name to register it\n",
    "        signature=signature,\n",
    "\n",
    "    )\n",
    "\n",
    "    model_uri = model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35dee80b-8289-4224-a1bc-bccf06016dbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : llmcup2024.default.agentqaxv2, Latest model version: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-73bab0af-d052-4e47-a9f0-1b/.ipykernel/52959/command-2586615384031825-4153226305:9: LangChainDeprecationWarning: The class `ChatDatabricks` was deprecated in LangChain 0.3.3 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-databricks package and should be used instead. To use it run `pip install -U :class:`~langchain-databricks` and import as `from :class:`~langchain_databricks import ChatDatabricks``.\n  chat_model = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-405b-instruct\", max_tokens=4000)\n/home/spark-73bab0af-d052-4e47-a9f0-1b/.ipykernel/52959/command-2586615384031825-4153226305:73: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  llm_chain = LLMChain(llm=llm, prompt=feedback_prompt, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "######## Check model version ######## \n",
    "\n",
    "# Set the registry URI to Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get the latest version number of the specified model\n",
    "model_version_infos = client.search_model_versions(\"name = '%s'\" % model_name)\n",
    "if model_version_infos:\n",
    "    latest_model_version = max([model_version_info.version for model_version_info in model_version_infos])\n",
    "else:\n",
    "    raise(BaseException(\"Error: Model not created, verify if 00-Build-Model script ran successfully!\"))\n",
    "\n",
    "# Print the latest model version\n",
    "print(f\"Model : {model_name}, Latest model version: {latest_model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "957c32e7-8106-48a1-b31f-cab4e1d48d63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdacb6038dd416c90d027e40f2e1da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'messages': [{'role': 'user',\n",
       "    'content': 'get a youtube video on customer service greeting'},\n",
       "   {'content': '',\n",
       "    'additional_kwargs': {'tool_calls': [{'id': 'call_63f582b5-c0bb-436a-98c7-9c8419dbbf36',\n",
       "       'type': 'function',\n",
       "       'function': {'name': 'youtube_search',\n",
       "        'arguments': '{\"query\": \"customer service greeting\"}'}}]},\n",
       "    'response_metadata': {'prompt_tokens': 775,\n",
       "     'completion_tokens': 17,\n",
       "     'total_tokens': 792},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': 'run-88830ba3-6038-4866-85a0-2f84107f8480-0',\n",
       "    'example': False,\n",
       "    'tool_calls': [{'name': 'youtube_search',\n",
       "      'args': {'query': 'customer service greeting'},\n",
       "      'id': 'call_63f582b5-c0bb-436a-98c7-9c8419dbbf36',\n",
       "      'type': 'tool_call'}],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None},\n",
       "   {'content': \"['https://www.youtube.com/watch?v=oe6OXbzPj-I&pp=ygUZY3VzdG9tZXIgc2VydmljZSBncmVldGluZw%3D%3D', 'https://www.youtube.com/watch?v=LRJXMKZ4wOw&pp=ygUZY3VzdG9tZXIgc2VydmljZSBncmVldGluZw%3D%3D']\",\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'tool',\n",
       "    'name': 'youtube_search',\n",
       "    'id': None,\n",
       "    'tool_call_id': 'call_63f582b5-c0bb-436a-98c7-9c8419dbbf36',\n",
       "    'artifact': None,\n",
       "    'status': 'success'},\n",
       "   {'content': 'Here are the YouTube video results for \"customer service greeting\":\\n\\n1. **Video 1:** \"Customer Service Greeting\" by [Channel Name]\\n\\t* Link: https://www.youtube.com/watch?v=oe6OXbzPj-I\\n\\t* Description: Learn how to greet customers in a way that sets the tone for a positive experience. This video provides tips and examples of effective customer service greetings.\\n2. **Video 2:** \"The Ultimate Customer Service Greeting\" by [Channel Name]\\n\\t* Link: https://www.youtube.com/watch?v=LRJXMKZ4wOw\\n\\t* Description: Discover the secrets to delivering a customer service greeting that wows your customers. This video shares best practices and examples of greetings that can help you build trust and loyalty with your customers.\\n\\nPlease note that the channel names and descriptions are not provided in the response, so I had to fill in some placeholder text. If you want to get the actual channel names and descriptions, you would need to make another API call to retrieve that information.',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {'prompt_tokens': 920,\n",
       "     'completion_tokens': 223,\n",
       "     'total_tokens': 1143},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': 'run-3cb29ebf-b568-4e07-ae3f-c96422861aa6-0',\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None}]}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90c7af05-ac4f-41c2-92f8-bac4d4840aa9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "mlflow.set_experiment(experiment_id=\"1422264621101654\")\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d85f0e5-df47-4988-91ec-83bd11d5541e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0ea4c8894e407e845657b9070fe4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 01:49:33,924 52959 ERROR _handle_rpc_error GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.10/site-packages/pyspark/sql/connect/client/core.py\", line 1718, in config\n    resp = self._stub.Config(req, metadata=self.metadata())\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 439, in result\n    raise self\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1193, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1005, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=95586b35-1af2-47c8-bc23-ed97283b0fb8)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=95586b35-1af2-47c8-bc23-ed97283b0fb8)\", grpc_status:9, created_time:\"2024-10-27T01:49:33.92372058+00:00\"}\"\n>\n2024-10-27 01:49:33,924 52959 ERROR _handle_rpc_error GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.10/site-packages/pyspark/sql/connect/client/core.py\", line 1718, in config\n    resp = self._stub.Config(req, metadata=self.metadata())\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 439, in result\n    raise self\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1193, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1005, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=95586b35-1af2-47c8-bc23-ed97283b0fb8)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=95586b35-1af2-47c8-bc23-ed97283b0fb8)\", grpc_status:9, created_time:\"2024-10-27T01:49:33.92372058+00:00\"}\"\n>\n2024-10-27 01:49:35,915 52959 ERROR _handle_rpc_error GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.10/site-packages/pyspark/sql/connect/client/core.py\", line 1718, in config\n    resp = self._stub.Config(req, metadata=self.metadata())\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 439, in result\n    raise self\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1193, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1005, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=f5c81933-6890-4d05-822c-ca159266a796)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-10-27T01:49:35.915267371+00:00\", grpc_status:9, grpc_message:\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=f5c81933-6890-4d05-822c-ca159266a796)\"}\"\n>\n2024-10-27 01:49:35,915 52959 ERROR _handle_rpc_error GRPC Error received\nTraceback (most recent call last):\n  File \"/databricks/python/lib/python3.10/site-packages/pyspark/sql/connect/client/core.py\", line 1718, in config\n    resp = self._stub.Config(req, metadata=self.metadata())\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 439, in result\n    raise self\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1193, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n  File \"/databricks/python/lib/python3.10/site-packages/grpc/_channel.py\", line 1005, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=f5c81933-6890-4d05-822c-ca159266a796)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2024-10-27T01:49:35.915267371+00:00\", grpc_status:9, grpc_message:\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=27d58f41-c5ad-49cb-832c-56956fbdf3b4, reason=INACTIVITY_TIMEOUT]. (requestId=f5c81933-6890-4d05-822c-ca159266a796)\"}\"\n>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Here are the YouTube video results for \"customer service greeting\":\\n\\n1. **\"Customer Service Greeting Examples\"** by CareerBuilder (https://www.youtube.com/watch?v=oe6OXbzPj-I)\\n2. **\"Customer Service Greeting Script\"** by ServiceSkills (https://www.youtube.com/watch?v=b6GISKDhTps)\\n\\nYou can click on the links to watch the videos and learn more about customer service greetings!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-db23eb5b510e44f38e0bd6fc8f4307cf\"",
      "text/plain": [
       "Trace(request_id=tr-db23eb5b510e44f38e0bd6fc8f4307cf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model using the specified model URI\n",
    "model_uri = 'runs:/198b5c50c1a54946aae1b74d24e67a71/langgraph'\n",
    "\n",
    "loaded_model = mlflow.langchain.load_model(model_uri)\n",
    "\n",
    "# Define the input message for the model\n",
    "message = \"get a youtube video on customer service greeting\"\n",
    "input = {\"messages\": [{\"role\": \"user\", \"content\": message}]}\n",
    "\n",
    "# Invoke the loaded model with the input message\n",
    "response = loaded_model.invoke(input)\n",
    "\n",
    "# Print the content of the last message in the response\n",
    "display(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6ae8abe-6d9a-4661-8a95-5df47e8b2a79",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Mlflow run model log\n",
    "<img src ='./model_log.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef1d96a1-a1db-43d7-89d6-7f14862bf654",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Mlflow traces\n",
    "<img src ='./traces.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5904af0-3077-4692-a605-34a6a8c435e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Register model to catalog\n",
    "<img src ='./register_model.png'>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2586615384032080,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Mlflow_tracing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
