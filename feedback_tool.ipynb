{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56271880-8492-4359-8a7c-d6bf7c67cf61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_databricks import ChatDatabricks\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.tools import Tool, BaseTool\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0f8ffb5-ad67-4a1f-be49-157c4955c1db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\", max_tokens=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71f7d810-2cb0-4e45-9294-9414d251a8b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "feedback_prompt = PromptTemplate(\n",
    "    template=\"\"\"Given the following question {input}.\n",
    "    Provide training feedbacks for the mentioned customer support agent. \n",
    "    You must ask sql_agent to get the relevant qa_feedback_summary column from qa_table for the mentioned customer support agent and then summarize it. \n",
    "    Write a detailed response based on the qa_feedback_summary column from qa_table only. \n",
    "    You should NOT generate your own data.\n",
    "    You should NOT assume any data or returned data.\n",
    "    You can end with a training plan for the customer support agent to improve the weakest area. \n",
    "    When confronted with choices, make a decision yourself with reasoning.\n",
    "    \"\"\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=feedback_prompt, verbose=False)\n",
    "\n",
    "llm_chain1 = (\n",
    "    feedback_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c4bd11d-0433-4b2a-a06a-ddb73d2ea185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feedback_tool = Tool(\n",
    "    name=\"feedback_agent\",\n",
    "    func=llm_chain.run,\n",
    "    description=\"useful for providing training feedbacks based on qa_feedback_summary from sql_agent\",\n",
    "    handle_tool_error = True,\n",
    "    verbose = False, \n",
    "    error_message = \"Error running feedback tool\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "feedback_tool",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
